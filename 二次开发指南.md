# Open Notebook + LongCut äºŒæ¬¡å¼€å‘æŒ‡å—

> åŸºäºä¸¤ä¸ªé¡¹ç›®çš„åŸå­èƒ½åŠ›è¿›è¡ŒäºŒæ¬¡å¼€å‘

---

## ğŸ“Š ä¸¤ä¸ªé¡¹ç›®å¯¹æ¯”æ€»è§ˆ

| ç»´åº¦ | Open Notebook | LongCut |
|------|---------------|---------|
| **å®šä½** | é€šç”¨ç ”ç©¶åŠ©æ‰‹ | YouTube è§†é¢‘å­¦ä¹ å·¥å…· |
| **æŠ€æœ¯æ ˆ** | Python + FastAPI + Next.js | Next.js 15 å…¨æ ˆ |
| **æ•°æ®åº“** | SurrealDB (åµŒå…¥å¼) | Supabase PostgreSQL |
| **éƒ¨ç½²æ–¹å¼** | Docker å®¹å™¨ | Vercel / Node.js |
| **AI æ¨¡å‹** | 16+ æä¾›å•† | 2 ä¸ª (Grok/Gemini) |
| **æœ¬åœ°åŒ–** | âœ… å®Œå…¨æœ¬åœ° | éœ€è¦äº‘æœåŠ¡ |

---

## ğŸ§© å¯å¤ç”¨çš„åŸå­èƒ½åŠ›æ¸…å•

### ä¸€ã€å†…å®¹å¤„ç†èƒ½åŠ›

| èƒ½åŠ› | æ¥æºé¡¹ç›® | æ–‡ä»¶ä½ç½® | è¯´æ˜ |
|------|----------|----------|------|
| PDF è§£æ | Open Notebook | `open_notebook/` | æå– PDF æ–‡æœ¬ |
| éŸ³é¢‘è½¬å½• | Open Notebook | `open_notebook/` | STT è¯­éŸ³è½¬æ–‡å­— |
| è§†é¢‘è½¬å½• | LongCut | `lib/` + `/api/transcript` | YouTube å­—å¹•è·å– |
| ç½‘é¡µæŠ“å– | Open Notebook | `open_notebook/` | Firecrawl/Jina |
| è½¬å½•åˆ†å— | LongCut | `lib/ai-processing.ts` | æ™ºèƒ½åˆ†å—é•¿æ–‡æœ¬ |
| å¥å­åˆå¹¶ | LongCut | `lib/transcript-sentence-merger.ts` | åˆå¹¶çŸ­å¥ |

### äºŒã€AI å¤„ç†èƒ½åŠ›

| èƒ½åŠ› | æ¥æºé¡¹ç›® | æ–‡ä»¶ä½ç½® | è¯´æ˜ |
|------|----------|----------|------|
| å¤šæ¨¡å‹æŠ½è±¡ | Open Notebook | `open_notebook/` | Esperanto åº“ |
| æä¾›å•†é€‚é… | LongCut | `lib/ai-providers/` | Grok/Gemini é€‚é…å™¨ |
| æç¤ºè¯æ¨¡æ¿ | Open Notebook | `prompts/*.jinja` | Jinja2 æ¨¡æ¿ |
| ç»“æ„åŒ–è¾“å‡º | LongCut | `lib/schemas.ts` | Zod æ¨¡å¼éªŒè¯ |
| æ¨¡å‹çº§è” | LongCut | `lib/ai-providers/` | è‡ªåŠ¨é™çº§é‡è¯• |

### ä¸‰ã€å†…å®¹ç”Ÿæˆèƒ½åŠ›

| èƒ½åŠ› | æ¥æºé¡¹ç›® | API/æ–‡ä»¶ | è¯´æ˜ |
|------|----------|----------|------|
| æ‘˜è¦ç”Ÿæˆ | ä¸¤è€…éƒ½æœ‰ | å„è‡ª API | å†…å®¹æ€»ç»“ |
| ä¸»é¢˜æå– | LongCut | `/api/generate-topics` | é«˜å…‰ä¸»é¢˜ |
| æ´å¯Ÿåˆ†æ | Open Notebook | `/insights` | AI è§è§£ |
| æ’­å®¢è„šæœ¬ | Open Notebook | `/podcasts` | å¤šè¯´è¯äººè„šæœ¬ |
| å»ºè®®é—®é¢˜ | LongCut | `/api/suggested-questions` | è®¨è®ºé—®é¢˜ |
| ç²¾å½©å¼•ç”¨ | LongCut | `/api/top-quotes` | è¯­å½•æå– |

### å››ã€å¯¹è¯èƒ½åŠ›

| èƒ½åŠ› | æ¥æºé¡¹ç›® | æ–‡ä»¶ä½ç½® | è¯´æ˜ |
|------|----------|----------|------|
| ä¸Šä¸‹æ–‡å¯¹è¯ | ä¸¤è€…éƒ½æœ‰ | `/chat` API | åŸºäºå†…å®¹å¯¹è¯ |
| å¼•ç”¨è¿½è¸ª | ä¸¤è€…éƒ½æœ‰ | å„è‡ªå®ç° | æ ‡æ³¨æ¥æº |
| å¼•ç”¨åŒ¹é… | LongCut | `lib/quote-matcher.ts` | ç²¾ç¡®åŒ¹é…ç®—æ³• |
| æ—¶é—´æˆ³å¼•ç”¨ | LongCut | å†…ç½® | è§†é¢‘æ—¶é—´æˆ³ |

### äº”ã€ç¬”è®°èƒ½åŠ›

| èƒ½åŠ› | æ¥æºé¡¹ç›® | API | è¯´æ˜ |
|------|----------|-----|------|
| å¤šæ¥æºç¬”è®° | ä¸¤è€…éƒ½æœ‰ | `/notes` | ä»å¤šå¤„åˆ›å»ºç¬”è®° |
| AI ç”Ÿæˆç¬”è®° | Open Notebook | `/notes` | è‡ªåŠ¨ç”Ÿæˆ |
| ç¬”è®°å¢å¼º | LongCut | `/api/notes/enhance` | AI ä¼˜åŒ–ç¬”è®° |
| è·¨å†…å®¹èšåˆ | LongCut | `/api/notes/all` | å…¨éƒ¨ç¬”è®°è§†å›¾ |

### å…­ã€æœç´¢èƒ½åŠ›

| èƒ½åŠ› | æ¥æºé¡¹ç›® | è¯´æ˜ |
|------|----------|------|
| å…¨æ–‡æœç´¢ | Open Notebook | å…³é”®è¯åŒ¹é… |
| å‘é‡æœç´¢ | Open Notebook | è¯­ä¹‰ç›¸ä¼¼åº¦ |
| æ··åˆæœç´¢ | Open Notebook | ç»“åˆä¸¤è€… |

### ä¸ƒã€ç¿»è¯‘èƒ½åŠ›

| èƒ½åŠ› | æ¥æºé¡¹ç›® | æ–‡ä»¶ä½ç½® | è¯´æ˜ |
|------|----------|----------|------|
| å®æ—¶ç¿»è¯‘ | LongCut | `lib/translation/` | å¤šè¯­è¨€ç¿»è¯‘ |
| æ‰¹é‡ç¿»è¯‘ | LongCut | `lib/translation-batcher.ts` | é«˜æ•ˆæ‰¹å¤„ç† |
| è¯­è¨€æ£€æµ‹ | LongCut | `lib/transcript-language.ts` | è‡ªåŠ¨æ£€æµ‹ |

### å…«ã€å®‰å…¨èƒ½åŠ›

| èƒ½åŠ› | æ¥æºé¡¹ç›® | æ–‡ä»¶ä½ç½® | è¯´æ˜ |
|------|----------|----------|------|
| CSRF ä¿æŠ¤ | LongCut | `lib/csrf-protection.ts` | ä»¤ç‰ŒéªŒè¯ |
| é€Ÿç‡é™åˆ¶ | LongCut | `lib/rate-limiter.ts` | API é™æµ |
| è¾“å…¥å‡€åŒ– | LongCut | `lib/sanitizer.ts` | XSS é˜²æŠ¤ |
| å¯†ç è®¤è¯ | Open Notebook | ä¸­é—´ä»¶ | ç®€å•å¯†ç ä¿æŠ¤ |

### ä¹ã€è¯­éŸ³èƒ½åŠ›

| èƒ½åŠ› | æ¥æºé¡¹ç›® | è¯´æ˜ |
|------|----------|------|
| è¯­éŸ³è½¬æ–‡å­— (STT) | Open Notebook | Whisper/Groq |
| æ–‡å­—è½¬è¯­éŸ³ (TTS) | Open Notebook | OpenAI/ElevenLabs |
| æ’­å®¢éŸ³é¢‘ç”Ÿæˆ | Open Notebook | å¤šè¯´è¯äººåˆæˆ |

---

## ğŸ¯ äºŒæ¬¡å¼€å‘åœºæ™¯å»ºè®®

### åœºæ™¯ 1: é€šç”¨è§†é¢‘å­¦ä¹ å¹³å°

**ç›®æ ‡**ï¼šç»“åˆä¸¤è€…ä¼˜åŠ¿ï¼Œæ”¯æŒå¤šç§è§†é¢‘æº

**ä½¿ç”¨çš„åŸå­èƒ½åŠ›**ï¼š
- LongCut: è½¬å½•åˆ†å—ã€ä¸»é¢˜æå–ã€å¼•ç”¨åŒ¹é…ã€ç¿»è¯‘
- Open Notebook: å¤šæ¨¡å‹æ”¯æŒã€å‘é‡æœç´¢ã€ç¬”è®°ç³»ç»Ÿ

**å®ç°æ€è·¯**ï¼š
```
1. ä½¿ç”¨ LongCut çš„å‰ç«¯æ¡†æ¶
2. æ›¿æ¢ AI åç«¯ä¸º Open Notebook çš„å¤šæ¨¡å‹æ¶æ„
3. æ·»åŠ  Open Notebook çš„å‘é‡æœç´¢èƒ½åŠ›
4. æ‰©å±•è§†é¢‘æºæ”¯æŒï¼ˆBç«™ã€æœ¬åœ°è§†é¢‘ç­‰ï¼‰
```

### åœºæ™¯ 2: ä¼ä¸šçŸ¥è¯†åº“

**ç›®æ ‡**ï¼šå†…éƒ¨æ–‡æ¡£ + è§†é¢‘åŸ¹è®­çš„ç»Ÿä¸€å­¦ä¹ å¹³å°

**ä½¿ç”¨çš„åŸå­èƒ½åŠ›**ï¼š
- Open Notebook: PDF/æ–‡æ¡£å¤„ç†ã€å‘é‡æœç´¢ã€æ’­å®¢ç”Ÿæˆ
- LongCut: è§†é¢‘å¤„ç†ã€ç¬”è®°ç³»ç»Ÿã€ç¿»è¯‘

**å®ç°æ€è·¯**ï¼š
```
1. ä½¿ç”¨ Open Notebook ä½œä¸ºåŸºç¡€
2. é›†æˆ LongCut çš„è§†é¢‘å¤„ç†æ¨¡å—
3. æ·»åŠ ä¼ä¸šè®¤è¯ï¼ˆLDAP/SSOï¼‰
4. éƒ¨ç½²ä¸ºç§æœ‰åŒ–æœåŠ¡
```

### åœºæ™¯ 3: AI æ’­å®¢å·¥ä½œå®¤

**ç›®æ ‡**ï¼šä»å¤šç§å†…å®¹æºç”Ÿæˆæ’­å®¢

**ä½¿ç”¨çš„åŸå­èƒ½åŠ›**ï¼š
- Open Notebook: æ’­å®¢è„šæœ¬ç”Ÿæˆã€TTSã€å¤šè¯´è¯äºº
- LongCut: è§†é¢‘è½¬å½•ã€ç²¾å½©å¼•ç”¨æå–

**å®ç°æ€è·¯**ï¼š
```
1. ä½¿ç”¨ Open Notebook çš„æ’­å®¢æ¨¡å—
2. æ·»åŠ  LongCut çš„è§†é¢‘å¤„ç†ä½œä¸ºè¾“å…¥æº
3. æ‰©å±•è¯´è¯äººé…ç½®
4. ä¼˜åŒ–éŸ³é¢‘è¾“å‡ºè´¨é‡
```

---

## ğŸ”§ æŠ€æœ¯æ•´åˆå»ºè®®

### 1. ç»Ÿä¸€ AI æŠ½è±¡å±‚

ä¸¤ä¸ªé¡¹ç›®éƒ½æœ‰ AI æŠ½è±¡ï¼Œå»ºè®®ç»Ÿä¸€ï¼š

```typescript
// ç»Ÿä¸€çš„ AI å®¢æˆ·ç«¯æ¥å£
interface AIClient {
  chat(messages: Message[], options?: ChatOptions): Promise<Response>
  embed(text: string): Promise<number[]>
  transcribe(audio: Buffer): Promise<string>
  speak(text: string, voice: string): Promise<Buffer>
}

// æä¾›å•†æ³¨å†Œ
const providers = {
  openai: OpenAIAdapter,
  anthropic: AnthropicAdapter,
  gemini: GeminiAdapter,
  grok: GrokAdapter,
  ollama: OllamaAdapter,
  // ...
}
```

### 2. ç»Ÿä¸€æ•°æ®æ¨¡å‹

```typescript
// ç»Ÿä¸€çš„å†…å®¹æºæ¨¡å‹
interface ContentSource {
  id: string
  type: 'pdf' | 'video' | 'audio' | 'webpage' | 'document'
  title: string
  content: string  // æå–çš„æ–‡æœ¬
  segments?: TranscriptSegment[]  // å¸¦æ—¶é—´æˆ³çš„ç‰‡æ®µ
  metadata: Record<string, any>
}

// ç»Ÿä¸€çš„ç¬”è®°æ¨¡å‹
interface Note {
  id: string
  userId: string
  sourceId: string
  sourceType: string
  text: string
  source: 'ai' | 'manual' | 'chat' | 'highlight'
  metadata?: {
    timestamp?: number
    citation?: string
    // ...
  }
}
```

### 3. æç¤ºè¯ç®¡ç†

å»ºè®®ä½¿ç”¨ Open Notebook çš„ Jinja2 æ¨¡æ¿æ–¹å¼ï¼š

```
prompts/
â”œâ”€â”€ chat/
â”‚   â”œâ”€â”€ general.jinja
â”‚   â”œâ”€â”€ video.jinja
â”‚   â””â”€â”€ document.jinja
â”œâ”€â”€ summary/
â”‚   â”œâ”€â”€ brief.jinja
â”‚   â””â”€â”€ detailed.jinja
â”œâ”€â”€ topics/
â”‚   â”œâ”€â”€ extract.jinja
â”‚   â””â”€â”€ generate.jinja
â””â”€â”€ podcast/
    â”œâ”€â”€ script.jinja
    â””â”€â”€ intro.jinja
```

---

## ğŸ“ é¡¹ç›®ä½ç½®

| é¡¹ç›® | è·¯å¾„ | ç«¯å£ |
|------|------|------|
| Open Notebook | `c:/Users/Li Hao/Desktop/open_notebook/` | 8502 (Web), 5055 (API) |
| LongCut | `c:/Users/Li Hao/Desktop/longcut/` | 3000 |

---

## âš ï¸ æ³¨æ„äº‹é¡¹

### Open Notebook
- âœ… å·²éƒ¨ç½²è¿è¡Œä¸­
- âš ï¸ éœ€è¦é…ç½®çœŸå®çš„ `OPENAI_API_KEY` æ‰èƒ½ä½¿ç”¨ AI åŠŸèƒ½
- é…ç½®æ–‡ä»¶ï¼š`c:/Users/Li Hao/Desktop/open_notebook/.env`

### LongCut
- âš ï¸ éœ€è¦ä»¥ä¸‹æœåŠ¡æ‰èƒ½å®Œæ•´è¿è¡Œï¼š
  1. **Supabase é¡¹ç›®** - æ•°æ®åº“å’Œè®¤è¯
  2. **Supadata API Key** - YouTube è½¬å½•æœåŠ¡
  3. **xAI æˆ– Gemini API Key** - AI åŠŸèƒ½
- é…ç½®æ–‡ä»¶ï¼š`c:/Users/Li Hao/Desktop/longcut/.env.local`

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å¯åŠ¨ Open Notebook
```powershell
cd "c:/Users/Li Hao/Desktop/open_notebook"
docker compose up -d
# è®¿é—® http://localhost:8502
```

### å¯åŠ¨ LongCut (éœ€è¦é…ç½® API Keys)
```powershell
cd "c:/Users/Li Hao/Desktop/longcut"
# å…ˆç¼–è¾‘ .env.local å¡«å…¥çœŸå®çš„ API Keys
npm run dev
# è®¿é—® http://localhost:3000
```

---

## ğŸ¤– æ·»åŠ æ–°çš„å¤§æ¨¡å‹ API æ”¯æŒ

### LongCut é¡¹ç›® - æ·»åŠ æ–°æ¨¡å‹æä¾›å•†

LongCut ä½¿ç”¨**é€‚é…å™¨æ¨¡å¼**ï¼Œæ·»åŠ æ–°æ¨¡å‹éå¸¸æ¸…æ™°ï¼š

#### æ­¥éª¤ 1: åˆ›å»ºé€‚é…å™¨æ–‡ä»¶

åœ¨ `lib/ai-providers/` ç›®å½•ä¸‹åˆ›å»ºæ–°é€‚é…å™¨ï¼Œä¾‹å¦‚ `openai-adapter.ts`ï¼š

```typescript
// lib/ai-providers/openai-adapter.ts
import { z } from 'zod';
import type { ProviderAdapter, ProviderGenerateParams, ProviderGenerateResult } from './types';

const PROVIDER_NAME = 'openai';
const DEFAULT_MODEL = 'gpt-4o';

export function createOpenAIAdapter(): ProviderAdapter {
  const apiKey = process.env.OPENAI_API_KEY;
  if (!apiKey) {
    throw new Error('OPENAI_API_KEY is required');
  }

  const baseUrl = process.env.OPENAI_API_BASE_URL ?? 'https://api.openai.com/v1';

  return {
    name: PROVIDER_NAME,
    defaultModel: DEFAULT_MODEL,
    async generate(params: ProviderGenerateParams): Promise<ProviderGenerateResult> {
      const requestStart = Date.now();
      
      const payload: Record<string, any> = {
        model: params.model ?? DEFAULT_MODEL,
        messages: [{ role: 'user', content: params.prompt }],
      };

      if (params.temperature !== undefined) payload.temperature = params.temperature;
      if (params.maxOutputTokens !== undefined) payload.max_tokens = params.maxOutputTokens;
      
      // ç»“æ„åŒ–è¾“å‡ºæ”¯æŒ
      if (params.zodSchema) {
        const jsonSchema = z.toJSONSchema(params.zodSchema);
        payload.response_format = {
          type: 'json_schema',
          json_schema: { name: params.schemaName ?? 'Response', schema: jsonSchema }
        };
      }

      const response = await fetch(`${baseUrl}/chat/completions`, {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${apiKey}`,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify(payload),
      });

      const data = await response.json();
      const latencyMs = Date.now() - requestStart;

      if (!response.ok) {
        throw new Error(`OpenAI API error: ${data.error?.message ?? 'Unknown'}`);
      }

      return {
        content: data.choices[0]?.message?.content ?? '',
        rawResponse: data,
        provider: PROVIDER_NAME,
        model: data.model,
        usage: {
          promptTokens: data.usage?.prompt_tokens,
          completionTokens: data.usage?.completion_tokens,
          totalTokens: data.usage?.total_tokens,
          latencyMs,
        },
      };
    },
  };
}
```

#### æ­¥éª¤ 2: æ³¨å†Œåˆ° registry

ä¿®æ”¹ `lib/ai-providers/registry.ts`ï¼š

```typescript
import { createGeminiAdapter } from './gemini-adapter';
import { createGrokAdapter } from './grok-adapter';
import { createOpenAIAdapter } from './openai-adapter';  // æ–°å¢
import type { ProviderAdapter, ProviderGenerateParams, ProviderGenerateResult } from './types';

type ProviderKey = 'grok' | 'gemini' | 'openai';  // æ·»åŠ  'openai'

const providerFactories: Record<ProviderKey, () => ProviderAdapter> = {
  grok: createGrokAdapter,
  gemini: createGeminiAdapter,
  openai: createOpenAIAdapter,  // æ–°å¢
};

const providerEnvGuards: Record<ProviderKey, () => string | undefined> = {
  grok: () => process.env.XAI_API_KEY,
  gemini: () => process.env.GEMINI_API_KEY,
  openai: () => process.env.OPENAI_API_KEY,  // æ–°å¢
};

// å…¶ä½™ä»£ç ä¸å˜...
```

#### æ­¥éª¤ 3: æ·»åŠ ç¯å¢ƒå˜é‡

åœ¨ `.env.local` ä¸­æ·»åŠ ï¼š

```bash
OPENAI_API_KEY=sk-your-openai-api-key
# å¯é€‰ï¼šè‡ªå®šä¹‰ API åœ°å€ï¼ˆç”¨äºä»£ç†æˆ–å…¼å®¹ APIï¼‰
OPENAI_API_BASE_URL=https://api.openai.com/v1
```

#### æ­¥éª¤ 4: å¯¼å‡ºé€‚é…å™¨ï¼ˆå¯é€‰ï¼‰

åœ¨ `lib/ai-providers/index.ts` ä¸­å¯¼å‡ºï¼š

```typescript
export { createOpenAIAdapter } from './openai-adapter';
```

---

### Open Notebook é¡¹ç›® - æ·»åŠ æ–°æ¨¡å‹æä¾›å•†

Open Notebook ä½¿ç”¨ **Esperanto** åº“ï¼Œå®ƒå·²å†…ç½®æ”¯æŒ 16+ æä¾›å•†ã€‚åªéœ€é…ç½®ç¯å¢ƒå˜é‡å³å¯ï¼š

#### å·²æ”¯æŒçš„æä¾›å•†ï¼ˆç›´æ¥é…ç½®å³å¯ï¼‰

| æä¾›å•† | ç¯å¢ƒå˜é‡ | ç¤ºä¾‹æ¨¡å‹ |
|--------|----------|----------|
| OpenAI | `OPENAI_API_KEY` | gpt-4o, gpt-4o-mini |
| Anthropic | `ANTHROPIC_API_KEY` | claude-3-5-sonnet |
| Google | `GOOGLE_API_KEY` | gemini-2.0-flash |
| Groq | `GROQ_API_KEY` | llama-3.3-70b |
| xAI | `XAI_API_KEY` | grok-2 |
| Ollama | `OLLAMA_HOST` | llama3, mistral |
| Azure OpenAI | `AZURE_OPENAI_*` | è‡ªå®šä¹‰éƒ¨ç½² |
| Mistral | `MISTRAL_API_KEY` | mistral-large |
| Cohere | `COHERE_API_KEY` | command-r-plus |
| Together | `TOGETHER_API_KEY` | å„ç§å¼€æºæ¨¡å‹ |
| Fireworks | `FIREWORKS_API_KEY` | å„ç§å¼€æºæ¨¡å‹ |
| DeepSeek | `DEEPSEEK_API_KEY` | deepseek-chat |
| OpenRouter | `OPENROUTER_API_KEY` | å¤šæ¨¡å‹è·¯ç”± |

#### é…ç½®æ­¥éª¤

1. ç¼–è¾‘ `.env` æ–‡ä»¶ï¼š

```bash
# æ·»åŠ æ–°çš„æä¾›å•† API Key
ANTHROPIC_API_KEY=sk-ant-your-key
GROQ_API_KEY=gsk_your-key
DEEPSEEK_API_KEY=sk-your-key
```

2. é‡å¯å®¹å™¨ï¼š

```powershell
cd "c:/Users/Li Hao/Desktop/open_notebook"
docker compose restart
```

3. åœ¨ Web ç•Œé¢çš„ **Settings** ä¸­é€‰æ‹©æ–°çš„æ¨¡å‹

#### æ·»åŠ è‡ªå®šä¹‰/ç§æœ‰æ¨¡å‹

å¦‚æœéœ€è¦æ·»åŠ  Esperanto ä¸æ”¯æŒçš„æä¾›å•†ï¼Œéœ€è¦ä¿®æ”¹ Python ä»£ç ï¼š

```python
# åœ¨ open_notebook/ai/ ç›®å½•ä¸‹åˆ›å»ºæ–°çš„æä¾›å•†
# å‚è€ƒ Esperanto åº“çš„é€‚é…å™¨æ¨¡å¼
```

---

### é€šç”¨ï¼šæ·»åŠ  OpenAI å…¼å®¹ API

å¾ˆå¤šå›½äº§æ¨¡å‹ï¼ˆå¦‚é€šä¹‰åƒé—®ã€æ™ºè°±ã€ç™¾å·ç­‰ï¼‰éƒ½æä¾› OpenAI å…¼å®¹ APIï¼Œå¯ä»¥é€šè¿‡ä¿®æ”¹ base URL æ¥å…¥ï¼š

#### LongCut æ–¹å¼

åˆ›å»ºä¸€ä¸ªé€šç”¨çš„ OpenAI å…¼å®¹é€‚é…å™¨ï¼š

```typescript
// lib/ai-providers/openai-compatible-adapter.ts
export function createOpenAICompatibleAdapter(config: {
  name: string;
  apiKey: string;
  baseUrl: string;
  defaultModel: string;
}): ProviderAdapter {
  return {
    name: config.name,
    defaultModel: config.defaultModel,
    async generate(params) {
      // ä½¿ç”¨æ ‡å‡† OpenAI API æ ¼å¼è°ƒç”¨
      const response = await fetch(`${config.baseUrl}/chat/completions`, {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${config.apiKey}`,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          model: params.model ?? config.defaultModel,
          messages: [{ role: 'user', content: params.prompt }],
          temperature: params.temperature,
          max_tokens: params.maxOutputTokens,
        }),
      });
      // ... å¤„ç†å“åº”
    },
  };
}

// ä½¿ç”¨ç¤ºä¾‹ï¼šæ¥å…¥é€šä¹‰åƒé—®
const qwenAdapter = createOpenAICompatibleAdapter({
  name: 'qwen',
  apiKey: process.env.DASHSCOPE_API_KEY!,
  baseUrl: 'https://dashscope.aliyuncs.com/compatible-mode/v1',
  defaultModel: 'qwen-max',
});
```

#### å¸¸è§å›½äº§æ¨¡å‹ API åœ°å€

| æ¨¡å‹ | Base URL | ç¯å¢ƒå˜é‡ |
|------|----------|----------|
| é€šä¹‰åƒé—® | `https://dashscope.aliyuncs.com/compatible-mode/v1` | `DASHSCOPE_API_KEY` |
| æ™ºè°± GLM | `https://open.bigmodel.cn/api/paas/v4` | `ZHIPU_API_KEY` |
| ç™¾å· | `https://api.baichuan-ai.com/v1` | `BAICHUAN_API_KEY` |
| æœˆä¹‹æš—é¢ Kimi | `https://api.moonshot.cn/v1` | `MOONSHOT_API_KEY` |
| DeepSeek | `https://api.deepseek.com` | `DEEPSEEK_API_KEY` |
| é›¶ä¸€ä¸‡ç‰© | `https://api.lingyiwanwu.com/v1` | `YI_API_KEY` |
| è®¯é£æ˜Ÿç« | `https://spark-api-open.xf-yun.com/v1` | `SPARK_API_KEY` |
| è…¾è®¯æ··å…ƒ | `https://api.hunyuan.cloud.tencent.com/v1` | `HUNYUAN_API_KEY` |

---

### å®Œæ•´ç¤ºä¾‹ï¼šä¸º LongCut æ·»åŠ  DeepSeek æ”¯æŒ

#### 1. åˆ›å»ºé€‚é…å™¨

```typescript
// lib/ai-providers/deepseek-adapter.ts
import type { ProviderAdapter, ProviderGenerateParams, ProviderGenerateResult } from './types';
import { z } from 'zod';

const PROVIDER_NAME = 'deepseek';
const DEFAULT_MODEL = 'deepseek-chat';

export function createDeepSeekAdapter(): ProviderAdapter {
  const apiKey = process.env.DEEPSEEK_API_KEY;
  if (!apiKey) {
    throw new Error('DEEPSEEK_API_KEY is required');
  }

  return {
    name: PROVIDER_NAME,
    defaultModel: DEFAULT_MODEL,
    async generate(params: ProviderGenerateParams): Promise<ProviderGenerateResult> {
      const requestStart = Date.now();
      
      const payload: Record<string, any> = {
        model: params.model ?? DEFAULT_MODEL,
        messages: [{ role: 'user', content: params.prompt }],
        stream: false,
      };

      if (params.temperature !== undefined) payload.temperature = params.temperature;
      if (params.maxOutputTokens !== undefined) payload.max_tokens = params.maxOutputTokens;
      
      if (params.zodSchema) {
        const jsonSchema = z.toJSONSchema(params.zodSchema);
        payload.response_format = {
          type: 'json_schema',
          json_schema: { name: params.schemaName ?? 'Response', schema: jsonSchema }
        };
      }

      const response = await fetch('https://api.deepseek.com/chat/completions', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${apiKey}`,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify(payload),
      });

      const data = await response.json();
      const latencyMs = Date.now() - requestStart;

      if (!response.ok) {
        throw new Error(`DeepSeek API error: ${data.error?.message ?? response.statusText}`);
      }

      return {
        content: data.choices[0]?.message?.content ?? '',
        rawResponse: data,
        provider: PROVIDER_NAME,
        model: data.model,
        usage: {
          promptTokens: data.usage?.prompt_tokens,
          completionTokens: data.usage?.completion_tokens,
          totalTokens: data.usage?.total_tokens,
          latencyMs,
        },
      };
    },
  };
}
```

#### 2. æ³¨å†Œé€‚é…å™¨

ä¿®æ”¹ `lib/ai-providers/registry.ts`ï¼š

```typescript
import { createDeepSeekAdapter } from './deepseek-adapter';

type ProviderKey = 'grok' | 'gemini' | 'deepseek';

const providerFactories: Record<ProviderKey, () => ProviderAdapter> = {
  grok: createGrokAdapter,
  gemini: createGeminiAdapter,
  deepseek: createDeepSeekAdapter,
};

const providerEnvGuards: Record<ProviderKey, () => string | undefined> = {
  grok: () => process.env.XAI_API_KEY,
  gemini: () => process.env.GEMINI_API_KEY,
  deepseek: () => process.env.DEEPSEEK_API_KEY,
};
```

#### 3. é…ç½®ç¯å¢ƒå˜é‡

åœ¨ `.env.local` ä¸­æ·»åŠ ï¼š

```bash
DEEPSEEK_API_KEY=sk-your-deepseek-key
AI_PROVIDER=deepseek  # å¯é€‰ï¼šè®¾ä¸ºé»˜è®¤æä¾›å•†
```

#### 4. é‡å¯é¡¹ç›®

```powershell
cd "c:/Users/Li Hao/Desktop/longcut"
npm run dev
```

---

## ğŸ“š å‚è€ƒæ–‡æ¡£

- Open Notebook: `c:/Users/Li Hao/Desktop/open_notebook/é¡¹ç›®åŠŸèƒ½åˆ†æ.md`
- LongCut: `c:/Users/Li Hao/Desktop/longcut/é¡¹ç›®åŠŸèƒ½åˆ†æ.md`
- LongCut æ¶æ„: `c:/Users/Li Hao/Desktop/longcut/CLAUDE.md`
- LongCut AI é€‚é…å™¨: `c:/Users/Li Hao/Desktop/longcut/lib/ai-providers/`
- Discussion é¡¹ç›®: `c:/Users/Li Hao/Desktop/discussion_new2/`
- Discussion API æŒ‡å—: `c:/Users/Li Hao/Desktop/discussion_new2/LLM_API_GUIDE.md`

---

## ğŸ™ï¸ Discussion é¡¹ç›®èƒ½åŠ›å¤ç”¨

ä½ çš„ `discussion_new2` é¡¹ç›®åŒ…å«ä¸‰ä¸ªæ ¸å¿ƒ API èƒ½åŠ›ï¼Œå¯ä»¥ç›´æ¥å¤ç”¨åˆ°å…¶ä»–é¡¹ç›®ï¼š

### é¡¹ç›®ä½ç½®

```
c:/Users/Li Hao/Desktop/discussion_new2/
â”œâ”€â”€ backend/src/modules/
â”‚   â”œâ”€â”€ llm/llm-adapter.service.ts          # é€šä¹‰åƒé—® (Qwen)
â”‚   â”œâ”€â”€ image-gen/image-generation-adapter.service.ts  # Gemini Imagen
â”‚   â””â”€â”€ tingwu/                              # é€šä¹‰å¬æ‚Ÿ
â”‚       â”œâ”€â”€ tingwu.service.ts                # ä»»åŠ¡ç®¡ç†
â”‚       â””â”€â”€ audio-relay.service.ts           # éŸ³é¢‘æµå¤„ç†
â””â”€â”€ LLM_API_GUIDE.md                         # è¯¦ç»† API æ–‡æ¡£
```

---

### èƒ½åŠ› 1: é€šä¹‰åƒé—® (Qwen) - æ–‡æœ¬ç”Ÿæˆ

**æ–‡ä»¶**: `backend/src/modules/llm/llm-adapter.service.ts`

**ç¯å¢ƒå˜é‡** (æ”¾åœ¨ `backend/.env`):
```bash
DASHSCOPE_API_KEY=sk-xxxxxxxx        # å¿…å¡«
LLM_MODEL=qwen3-max                  # å¯é€‰ï¼Œé»˜è®¤ qwen3-max
LLM_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=2000
```

**æ ¸å¿ƒæ¥å£**:
```typescript
// å¤šè½®å¯¹è¯
async chat(messages: ChatMessage[], options?: LLMOptions): Promise<string>

// å¸¦ç³»ç»Ÿæç¤ºè¯çš„å•è½®å¯¹è¯
async chatWithPrompt(systemPrompt: string, userContent: string, options?: LLMOptions): Promise<string>

// æµå¼è¾“å‡º
async chatStream(messages: ChatMessage[], onChunk: (chunk: string) => void, options?: LLMOptions): Promise<string>

// JSON å“åº”è§£æï¼ˆå¸¦å®¹é”™ï¼‰
async chatForJson<T>(messages: ChatMessage[], options?: LLMOptions): Promise<T | null>
```

**å¤ç”¨åˆ° LongCut**:

åˆ›å»º `lib/ai-providers/qwen-adapter.ts`:

```typescript
import type { ProviderAdapter, ProviderGenerateParams, ProviderGenerateResult } from './types';
import OpenAI from 'openai';

const PROVIDER_NAME = 'qwen';
const DEFAULT_MODEL = 'qwen3-max';

export function createQwenAdapter(): ProviderAdapter {
  const apiKey = process.env.DASHSCOPE_API_KEY;
  if (!apiKey) {
    throw new Error('DASHSCOPE_API_KEY is required');
  }

  const client = new OpenAI({
    apiKey,
    baseURL: process.env.LLM_BASE_URL ?? 'https://dashscope.aliyuncs.com/compatible-mode/v1',
  });

  return {
    name: PROVIDER_NAME,
    defaultModel: DEFAULT_MODEL,
    async generate(params: ProviderGenerateParams): Promise<ProviderGenerateResult> {
      const requestStart = Date.now();
      
      const completion = await client.chat.completions.create({
        model: params.model ?? DEFAULT_MODEL,
        messages: [{ role: 'user', content: params.prompt }],
        temperature: params.temperature,
        max_tokens: params.maxOutputTokens,
        stream: false,
      });

      const latencyMs = Date.now() - requestStart;

      return {
        content: completion.choices[0]?.message?.content ?? '',
        rawResponse: completion,
        provider: PROVIDER_NAME,
        model: completion.model,
        usage: {
          promptTokens: completion.usage?.prompt_tokens,
          completionTokens: completion.usage?.completion_tokens,
          totalTokens: completion.usage?.total_tokens,
          latencyMs,
        },
      };
    },
  };
}
```

---

### èƒ½åŠ› 2: Gemini Imagen - å›¾åƒç”Ÿæˆ

**æ–‡ä»¶**: `backend/src/modules/image-gen/image-generation-adapter.service.ts`

**ç¯å¢ƒå˜é‡**:
```bash
GEMINI_API_KEY=AIzaSyxxxxxxxxxx        # å¿…å¡«
IMAGE_GEN_MODEL=gemini-2.5-flash-image  # æˆ– imagen-3.0-generate-001
IMAGE_GEN_BASE_URL=https://generativelanguage.googleapis.com/v1beta
IMAGE_GEN_SIZE=1024x1024
```

**æ ¸å¿ƒæ¥å£**:
```typescript
interface ImageGenerationResult {
  url?: string;
  base64?: string;
  metadata?: any;
}

async generate(prompt: string, options?: ImageGenerationOptions): Promise<ImageGenerationResult>
```

**å¤ç”¨åˆ° LongCut** (åˆ›å»º `lib/image-generation.ts`):

```typescript
export interface ImageGenerationResult {
  base64?: string;
  metadata?: any;
}

export async function generateImage(prompt: string, options?: {
  size?: string;
  aspectRatio?: string;
}): Promise<ImageGenerationResult> {
  const apiKey = process.env.GEMINI_API_KEY;
  if (!apiKey) throw new Error('GEMINI_API_KEY not configured');

  const model = process.env.IMAGE_GEN_MODEL ?? 'gemini-2.5-flash-image';
  const baseUrl = process.env.IMAGE_GEN_BASE_URL ?? 'https://generativelanguage.googleapis.com/v1beta';
  
  const url = `${baseUrl}/models/${model}:generateContent`;

  const response = await fetch(url, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'x-goog-api-key': apiKey,
    },
    body: JSON.stringify({
      contents: [{ parts: [{ text: prompt }] }],
      generationConfig: {
        responseModalities: ['IMAGE'],
        aspectRatio: options?.aspectRatio ?? '1:1',
      },
    }),
  });

  if (!response.ok) {
    throw new Error(`Gemini Image API error: ${response.status}`);
  }

  const data = await response.json();
  
  // æå– Base64 å›¾åƒ
  const candidate = data.candidates?.[0];
  const inlineData = candidate?.content?.parts?.[0]?.inlineData;
  
  if (inlineData?.data) {
    return {
      base64: inlineData.data,
      metadata: { mimeType: inlineData.mimeType },
    };
  }

  throw new Error('No image data in response');
}
```

---

### èƒ½åŠ› 3: é€šä¹‰å¬æ‚Ÿ - å®æ—¶è¯­éŸ³è½¬æ–‡æœ¬

**æ–‡ä»¶**: 
- `backend/src/modules/tingwu/tingwu.service.ts` - ä»»åŠ¡ç®¡ç†
- `backend/src/modules/tingwu/audio-relay.service.ts` - éŸ³é¢‘æµå¤„ç†

**ç¯å¢ƒå˜é‡**:
```bash
TINGWU_ACCESS_KEY_ID=LTAI5txxxxxxxxxx      # å¿…å¡«
TINGWU_ACCESS_KEY_SECRET=xxxxxxxxxxxxxxxx  # å¿…å¡«
TINGWU_APP_KEY=xxxxxxxxxxxxxxxx            # å¿…å¡«
TINGWU_REGION=cn-beijing
```

**ä¾èµ–åŒ…**:
```json
{
  "@alicloud/tingwu20230930": "^1.x",
  "@alicloud/openapi-client": "^0.x",
  "ws": "^8.x",
  "ffmpeg-static": "^5.x"
}
```

**æ ¸å¿ƒæµç¨‹**:

```typescript
// 1. åˆ›å»ºå®æ—¶è½¬å†™ä»»åŠ¡
const { taskId, meetingJoinUrl } = await tingwuService.createRealtimeTask({
  meetingId: 'meeting-123',
});

// 2. å»ºç«‹ WebSocket è¿æ¥
const socket = new WebSocket(meetingJoinUrl);

// 3. å‘é€å¼€å§‹å‘½ä»¤
socket.send(JSON.stringify({
  header: { name: 'StartTranscription', namespace: 'SpeechTranscriber' },
  payload: { format: 'pcm', sample_rate: 16000 },
}));

// 4. å‘é€ PCM éŸ³é¢‘æ•°æ®ï¼ˆéœ€è¦å…ˆç”¨ ffmpeg è½¬æ¢ï¼‰
// æ ¼å¼è¦æ±‚ï¼šPCM 16ä½å°ç«¯, 16kHz, å•å£°é“
socket.send(pcmBuffer);

// 5. æ¥æ”¶è½¬å†™ç»“æœ
socket.on('message', (data) => {
  const msg = JSON.parse(data);
  if (msg.header?.name === 'SentenceEnd') {
    console.log('è½¬å†™ç»“æœ:', msg.payload?.result);
  }
});

// 6. åœæ­¢è½¬å†™
socket.send(JSON.stringify({
  header: { name: 'StopTranscription', namespace: 'SpeechTranscriber' },
  payload: {},
}));
```

**éŸ³é¢‘æ ¼å¼è½¬æ¢** (WebM â†’ PCM):

```typescript
import { spawn } from 'child_process';
import ffmpeg from 'ffmpeg-static';

function convertToPcm(webmBuffer: Buffer): Promise<Buffer> {
  return new Promise((resolve, reject) => {
    const proc = spawn(ffmpeg!, [
      '-loglevel', 'error',
      '-f', 'webm',
      '-i', 'pipe:0',
      '-vn',
      '-acodec', 'pcm_s16le',
      '-ar', '16000',
      '-ac', '1',
      '-f', 's16le',
      'pipe:1',
    ], { stdio: ['pipe', 'pipe', 'pipe'] });

    const chunks: Buffer[] = [];
    proc.stdout?.on('data', (chunk) => chunks.push(chunk));
    proc.on('close', () => resolve(Buffer.concat(chunks)));
    proc.on('error', reject);

    proc.stdin?.write(webmBuffer);
    proc.stdin?.end();
  });
}
```

---

### å¿«é€Ÿå¤ç”¨æ–¹å¼

**æ–¹å¼ 1: ç›´æ¥å¼•ç”¨æºæ–‡ä»¶**

å¦‚æœé¡¹ç›®éƒ½åœ¨æœ¬åœ°ï¼Œå¯ä»¥ç›´æ¥ importï¼š

```typescript
// åœ¨ LongCut ä¸­å¼•ç”¨ Discussion çš„æœåŠ¡
import { LLMAdapterService } from '../../discussion_new2/backend/src/modules/llm/llm-adapter.service';
```

**æ–¹å¼ 2: å¤åˆ¶æ ¸å¿ƒä»£ç **

å°†ä»¥ä¸‹æ–‡ä»¶å¤åˆ¶åˆ°ç›®æ ‡é¡¹ç›®ï¼š
- `llm-adapter.service.ts` â†’ æ–‡æœ¬ç”Ÿæˆ
- `image-generation-adapter.service.ts` â†’ å›¾åƒç”Ÿæˆ
- `tingwu.service.ts` + `audio-relay.service.ts` â†’ è¯­éŸ³è½¬æ–‡æœ¬

**æ–¹å¼ 3: åˆ›å»ºå…±äº« npm åŒ…**

å°†è¿™äº›æœåŠ¡æŠ½å–ä¸ºç‹¬ç«‹çš„ npm åŒ…ï¼Œä¾›å¤šä¸ªé¡¹ç›®ä½¿ç”¨ã€‚

---

### ç¯å¢ƒå˜é‡æ±‡æ€»

åœ¨ `backend/.env` ä¸­é…ç½®æ‰€æœ‰ APIï¼š

```bash
# ===== é€šä¹‰åƒé—® (Qwen) =====
DASHSCOPE_API_KEY=sk-xxxxxxxx
LLM_MODEL=qwen3-max
LLM_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=2000

# ===== Gemini Imagen =====
GEMINI_API_KEY=AIzaSyxxxxxxxxxx
IMAGE_GEN_MODEL=gemini-2.5-flash-image
IMAGE_GEN_BASE_URL=https://generativelanguage.googleapis.com/v1beta
IMAGE_GEN_SIZE=1024x1024

# ===== é€šä¹‰å¬æ‚Ÿ =====
TINGWU_ACCESS_KEY_ID=LTAI5txxxxxxxxxx
TINGWU_ACCESS_KEY_SECRET=xxxxxxxxxxxxxxxx
TINGWU_APP_KEY=xxxxxxxxxxxxxxxx
TINGWU_REGION=cn-beijing
```

---

### ä¸‰ä¸ªé¡¹ç›®èƒ½åŠ›å¯¹æ¯”

| èƒ½åŠ› | Open Notebook | LongCut | Discussion |
|------|---------------|---------|------------|
| **æ–‡æœ¬ç”Ÿæˆ** | 16+ æä¾›å•† | Grok/Gemini | é€šä¹‰åƒé—® |
| **å›¾åƒç”Ÿæˆ** | âŒ | âŒ | âœ… Gemini Imagen |
| **è¯­éŸ³è½¬æ–‡æœ¬** | Whisper/Groq | Supadata | âœ… é€šä¹‰å¬æ‚Ÿ (å®æ—¶) |
| **è§†é¢‘å¤„ç†** | æœ¬åœ°è§†é¢‘ | YouTube | âŒ |
| **å‘é‡æœç´¢** | âœ… | âŒ | âŒ |
| **æ’­å®¢ç”Ÿæˆ** | âœ… | âŒ | âŒ |

**æœ€ä½³ç»„åˆå»ºè®®**ï¼š
- æ–‡æœ¬ç”Ÿæˆï¼šä½¿ç”¨ Discussion çš„é€šä¹‰åƒé—®ï¼ˆå›½å†…è®¿é—®å¿«ï¼‰æˆ– LongCut çš„å¤šæä¾›å•†æ¶æ„
- å›¾åƒç”Ÿæˆï¼šä½¿ç”¨ Discussion çš„ Gemini Imagen
- è¯­éŸ³è½¬æ–‡æœ¬ï¼šä½¿ç”¨ Discussion çš„é€šä¹‰å¬æ‚Ÿï¼ˆå®æ—¶æµå¼ï¼Œæ”¯æŒä¸­æ–‡ï¼‰
- è§†é¢‘å¤„ç†ï¼šä½¿ç”¨ LongCut çš„ YouTube å¤„ç† + Open Notebook çš„æœ¬åœ°è§†é¢‘
- çŸ¥è¯†ç®¡ç†ï¼šä½¿ç”¨ Open Notebook çš„å‘é‡æœç´¢å’Œç¬”è®°ç³»ç»Ÿ
